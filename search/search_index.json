{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#homelab-documentation","title":"Homelab Documentation","text":"<p>Welcome to my personal homelab documentation repository. This repo tracks the setup, configuration, and operational practices for my self-hosted infrastructure \u2014 designed with production-level standards in mind.</p>"},{"location":"#overview","title":"Overview","text":"<p>This homelab is built on:</p> <ul> <li>Proxmox VE 8.4.1 as the hypervisor</li> <li>ZFS (RAID 1) for resilient local storage</li> <li>Automated snapshot management</li> <li>Containerized services like Pi-hole, Grafana, and more</li> <li>Full documentation built with MkDocs + Material Theme</li> </ul>"},{"location":"#folder-structure","title":"Folder Structure","text":"<pre><code>homelab-docs/\n\u251c\u2500\u2500 docs/\n\u2502 \u251c\u2500\u2500 index.md # Homepage for MkDocs\n\u2502 \u251c\u2500\u2500 guides/\n\u2502 \u2502 \u2514\u2500\u2500 mkdocs_deploy_guide.md # How to deploy this doc site\n\u2502 \u251c\u2500\u2500 infrastructure/\n\u2502 \u2502 \u2514\u2500\u2500 proxmox_setup.md # ZFS, RAID1, BIOS setup\n\u2502 \u251c\u2500\u2500 services/\n\u2502 \u2502 \u2514\u2500\u2500 pihole/\n\u2502 \u2502 \u2514\u2500\u2500 config_notes.md # Pi-hole LXC container setup\n\u2502 \u251c\u2500\u2500 monitoring/\n\u2502 \u2502 \u2514\u2500\u2500 grafana_setup.md # Grafana, uptime monitoring stack\n\u251c\u2500\u2500 mkdocs.yml # MkDocs site configuration\n\u251c\u2500\u2500 .gitignore # Git ignored files\n\u2514\u2500\u2500 README.md # GitHub landing page (this file)\n</code></pre>"},{"location":"#live-docs","title":"Live Docs","text":"<p>View the full, browsable documentation site:</p> <p>\ud83d\udd17 https://tylerwkoontz.github.io/homelab-docs/</p>"},{"location":"#goals","title":"Goals","text":"<ul> <li>\u2705 Learn and document real-world infrastructure practices</li> <li>\u2705 Host and monitor my own stack</li> <li>\u2705 Build a project portfolio for future cloud/infrastructure roles</li> <li>\u2705 Make my setup reproducible for others</li> </ul>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>ZFS mirror with automatic snapshotting</li> <li>Clean documentation flow with MkDocs + Material</li> <li>Air-gapped service isolation via containers</li> <li>Everything reproducible, version-controlled, and platform-ready</li> </ul>"},{"location":"#future-plans","title":"Future Plans","text":"<ul> <li>Add Ansible playbooks for provisioning</li> <li>Set up off-site snapshot syncing</li> <li>Integrate Prometheus &amp; Grafana alerting</li> <li>Deploy more services: Vaultwarden, Jellyfin, Home Assistant</li> </ul>"},{"location":"#contact","title":"Contact","text":"<p>Built and maintained by Tyler Koontz</p>"},{"location":"infrastructure/proxmox-setup/","title":"Proxmox Setup &amp; ZFS RAID Configuration","text":""},{"location":"infrastructure/proxmox-setup/#overview","title":"Overview","text":"<p>This document outlines the installation and configuration of <code>pve1</code>, the primary Proxmox node in my homelab. It includes the setup of Proxmox VE 8.4.1 using a macOS-flashed USB, configuration of the Dell H730 Mini controller in HBA (IT) mode, and the deployment of a ZFS mirror (RAID 1) across two 2TB SAS drives. ZFS automatic snapshots have been enabled to provide versioned backups and rollback points.</p> <p>This setup prioritizes data integrity, service reliability, and future scalability. All steps are documented to ensure clarity.</p>"},{"location":"infrastructure/proxmox-setup/#system-summary","title":"System Summary","text":"<ul> <li>Node: pve1</li> <li>Hardware: Dell PowerEdge R430</li> <li>Drives: 2 \u00d7 2TB SAS</li> <li>Proxmox Version: 8.4.1</li> <li>Storage Type: ZFS Mirror (RAID 1)</li> </ul>"},{"location":"infrastructure/proxmox-setup/#step-by-step-installation","title":"Step-by-Step Installation","text":""},{"location":"infrastructure/proxmox-setup/#1-flash-proxmox-iso-to-usb","title":"1. Flash Proxmox ISO to USB","text":"<p>Used macOS terminal tools instead of GUI software:</p> <pre><code># Convert the ISO to a raw disk image format (.dmg) suitable for writing to USB\nhdiutil convert -format UDRW -o proxmox-ve_8.4-1.dmg ~/Downloads/proxmox-ve_8.4-1.iso\n\n# List all disks to identify the USB drive (e.g., /dev/disk2)\ndiskutil list\n\n# Unmount the USB drive so it can be written to directly\ndiskutil unmountDisk /dev/disk2\n\n# Write the .dmg image to the USB drive using raw access (note the 'r' in rdisk2 for faster write)\nsudo dd if=proxmox-ve_8.4-1.dmg of=/dev/rdisk2 bs=1m\n</code></pre> <p>Why: Using the macOS CLI gives more control over the flashing process, avoids GUI tools, and allows installing Proxmox directly from a clean bootable USB. Writing the ISO to USB ensures the OS lives on its own device, keeping the primary drives available for dedicated ZFS storage.</p>"},{"location":"infrastructure/proxmox-setup/#2-configure-bios-and-storage-controller","title":"2. Configure BIOS and Storage Controller","text":"<ul> <li>Set USB as the primary boot device to ensure the Proxmox installer loads first.</li> <li>Configured the H730 Mini RAID controller into HBA (IT) mode to allow ZFS direct access to raw disks.</li> <li>Verified both 2TB drives were exposed individually (non-RAID) to the Proxmox installer.</li> </ul> <p>Why: ZFS requires direct access to physical disks for redundancy and integrity features. HBA mode bypasses the RAID logic, making the drives visible as raw block devices to the OS without removing the controller.</p>"},{"location":"infrastructure/proxmox-setup/#zfs-raid-1-setup","title":"ZFS RAID 1 Setup","text":""},{"location":"infrastructure/proxmox-setup/#1-created-zfs-mirror-pool","title":"1. Created ZFS Mirror Pool","text":"<p>Used the Proxmox web UI during installation: - Selected ZFS RAID 1 (mirror) using <code>/dev/sda</code> and <code>/dev/sdb</code> - Accepted the default pool name: <code>rpool</code></p> <p>ZFS provides: - Built-in redundancy via mirroring (RAID 1) - Data integrity through checksumming and self-healing - Efficient snapshots for backups and rollback - SMART integration to monitor drive health and predict failure (<code>zpool status</code> and <code>smartctl</code> both supported natively)</p> <p>Note to self (future plan): Once the remaining 6 drives are installed, plan to: - Expand to a RAID-Z2 or multiple mirror vdevs - Create a separate storage pool for high-capacity or tiered storage use - Consider setting up ZFS alerts and monitoring via Grafana or Prometheus</p>"},{"location":"infrastructure/proxmox-setup/#zfs-automatic-snapshots","title":"ZFS Automatic Snapshots","text":""},{"location":"infrastructure/proxmox-setup/#tool-used","title":"Tool Used","text":"<p>Installed <code>zfs-auto-snapshot</code>, which adds automated, scheduled snapshots using system cron jobs.</p> <pre><code>apt update\napt install zfs-auto-snapshot -y\n</code></pre>"},{"location":"infrastructure/proxmox-setup/#default-retention-policy","title":"Default Retention Policy","text":"<p>Once installed, snapshots are created and rotated automatically: - Hourly: 24 retained - Daily: 7 retained - Weekly: 4 retained - Monthly: 12 retained</p> <p>Snapshots are stored within the same dataset and do not consume extra space unless data changes (copy-on-write).</p> <p>Verify Snapshots To view existing snapshots:</p> <pre><code>zfs list -t snapshot\n</code></pre> <p>Why It Matters - Provides automatic rollback points for VMs and datasets - Enables rapid recovery from misconfiguration, corruption, or deletion - Integrates with ZFS-native features like rollback and replication - Supports SMART-based storage and future offsite backup plans</p> <p>Note to Self - Plan to integrate snapshot monitoring with Grafana or Prometheus - Future: Automate off-node snapshot syncing for cold storage redundancy</p> <p>Optional: Exclude specific datasets with:</p> <pre><code>zfs set com.sun:auto-snapshot=false rpool/data/iso-store\n</code></pre>"},{"location":"infrastructure/proxmox-setup/#notes","title":"Notes","text":"<ul> <li>Proxmox 8.4.1 was installed via a bootable USB created using macOS CLI tools (<code>dd</code>, <code>hdiutil</code>) for maximum control and precision.</li> <li>The Dell H730 Mini controller was left installed but switched to HBA (IT) mode, allowing Proxmox/ZFS direct access to raw disks.</li> <li>No hardware RAID is used \u2014 ZFS software RAID 1 (mirror) provides redundancy, integrity checking, and snapshot capability.</li> <li>Automatic snapshots (<code>zfs-auto-snapshot</code>) are scheduled hourly, daily, weekly, and monthly using cron, enabling lightweight rollback and recovery.</li> <li>SMART monitoring is natively supported in ZFS; future plans include logging and alerting via Grafana/Prometheus stack.</li> <li>ZFS snapshots are copy-on-write and live within the same datasets, requiring minimal space unless data changes.</li> <li>All configurations were documented from the beginning to ensure traceability, reproducibility, and showcase-level professionalism.</li> <li>Plans to expand storage to RAID-Z2 or multiple vdev mirrors with six additional drives for higher capacity and resilience.</li> <li>Future snapshot syncing and backup strategy will include off-node replication or cold storage, improving disaster recovery posture.</li> </ul>"},{"location":"monitoring/grafana_setup/","title":"Grafana Monitoring Setup","text":"<p>Status: \ud83d\udea7 This section is currently under construction.</p> <p>This page will document the setup and configuration of Grafana in my homelab. It will include:</p> <ul> <li>How Grafana connects to data sources (e.g., InfluxDB, Pi-hole, Uptime Kuma)</li> <li>Dashboards for system metrics, network performance, DNS logs</li> <li>Deployment method (Docker Compose, LXC, etc.)</li> <li>Access control and reverse proxy setup (e.g., Nginx + Auth)</li> </ul>"},{"location":"monitoring/grafana_setup/#whats-planned","title":"What\u2019s Planned","text":"<ul> <li>[ ] Install Grafana in Docker or LXC</li> <li>[ ] Connect to Prometheus or Uptime Kuma</li> <li>[ ] Create custom dashboards for ZFS, Proxmox, and DNS</li> <li>[ ] Secure admin interface with login + HTTPS</li> <li>[ ] Integrate with MkDocs site for visual previews</li> </ul> <p>Note to Self: This page is stubbed to maintain project structure and signal future documentation goals.</p> <p>Return to Monitoring Overview</p>"},{"location":"services/pihole/config_notes/","title":"Pi-hole Configuration Notes","text":"<p>This document outlines the rationale, setup process, and configuration details of the Pi-hole DNS filtering service running in my homelab.</p> <p>Detailed installation steps in Proxmox</p>"},{"location":"services/pihole/config_notes/#overview","title":"Overview","text":"<p>Pi-hole is a network-level ad blocker that intercepts DNS queries and blocks known ad/tracking domains before they reach client devices.</p>"},{"location":"services/pihole/config_notes/#why-i-use-it","title":"Why I Use It","text":"<ul> <li>Reduces ads and tracking across all devices</li> <li>Improves page load times</li> <li>Helps monitor network-level DNS activity</li> <li>Protects against malicious domains</li> </ul>"},{"location":"services/pihole/config_notes/#deployment-details","title":"Deployment Details","text":"Component Value Host <code>pve1</code> Container LXC (Unprivileged, Nesting) OS Template Debian 12 (Turnkey) IP Address <code>192.168.1.4</code> (static) Pi-hole Version Installed via official curl script Web UI Port <code>80</code>"},{"location":"services/pihole/config_notes/#install-process-inside-lxc","title":"Install Process (Inside LXC)","text":"<pre><code>apt update &amp;&amp; apt upgrade -y\ncurl -sSL https://install.pi-hole.net | bash\n</code></pre> <p>During install: - Selected upstream DNS provider (Cloudflare) - Set static IP manually (192.168.79.10) - Enabled web admin interface - Default blocklists were applied (for now)</p>"},{"location":"services/pihole/config_notes/#admin-interface","title":"Admin Interface","text":"<p>Access via: http://192.168.1.2/admin</p> <p>Set password:</p> <pre><code>pihole -a -p\n</code></pre>"},{"location":"services/pihole/config_notes/#dns-configuration","title":"DNS Configuration","text":"<p>Router-Level: - DHCP DNS server points to Pi-hole's IP - IPv6 filtering disabled (for now)</p> <p>Client-Level (fallback): - Some devices manually configured to use Pi-hole as DNS resolver</p>"},{"location":"services/pihole/config_notes/#monitoring-logs","title":"Monitoring &amp; Logs","text":"<ul> <li>Query log available in web UI</li> <li>Block/allow domains via dashboard</li> <li>Consider future integration with Grafana/InfluxDB for visual DNS monitoring</li> </ul>"},{"location":"services/pihole/config_notes/#why-lxc-instead-of-docker","title":"Why LXC Instead of Docker?","text":"<ul> <li>Easier networking setup on Proxmox</li> <li>Lower overhead than full VM</li> <li>Better integration with snapshotting and backup via Proxmox GUI</li> </ul>"},{"location":"services/pihole/config_notes/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Replace or test with AdGuard Home</li> <li>Add fail2ban for admin UI brute-force protection</li> <li>Schedule regular Pi-hole config backups</li> <li>Expose via Tailscale or reverse proxy with Auth if remote access needed</li> </ul>"},{"location":"services/pihole/proxmox_pihole_setup/","title":"Proxmox Pi-hole Setup (LXC) \u2013 With Explanations","text":"<p>Back to Pi-hole overview and rationale</p>"},{"location":"services/pihole/proxmox_pihole_setup/#1-download-a-base-lxc-template","title":"1. Download a Base LXC Template","text":"<p>Proxmox Web UI \u2192 <code>pve1</code> \u2192 <code>local</code> \u2192 CT Templates \u2192 Templates \u2192 Download Debian 12 or Ubuntu 22.04</p> <p>Why: - Minimal, stable, widely supported. - Debian is Pi-hole recommended. - Needed to create containers.</p>"},{"location":"services/pihole/proxmox_pihole_setup/#2-create-an-lxc-container","title":"2. Create an LXC Container","text":"<p>In the Proxmox Web UI:</p> <ul> <li>Unprivileged Container: \u2705 Checked Why: Improves security by isolating container root from host root.</li> <li>Features &gt; Nesting: \u2705 Checked Why: Needed for systemd and services like dnsmasq.</li> <li>Disk Size: 4\u20138GB (ZFS-backed)</li> <li>CPU / RAM: 1 vCPU, 512MB\u20131GB RAM</li> <li>Network: DHCP (we'll set static IP later)</li> <li>Container Name: <code>pihole</code></li> </ul>"},{"location":"services/pihole/proxmox_pihole_setup/#3-set-static-ip-recommended","title":"3. Set Static IP (Recommended)","text":"<p>Access console:</p> <pre><code>pct console 100  # Replace 100 with your CT ID\n</code></pre> <p>Edit interfaces (Debian example):</p> <pre><code>nano /etc/network/interfaces\n</code></pre> <pre><code>auto eth0\niface eth0 inet static\n  address 192.168.79.10\n  netmask 255.255.255.0\n  gateway 192.168.79.1\n  dns-nameservers 1.1.1.1 8.8.8.8\n</code></pre> <pre><code>reboot\n</code></pre> <p>Why: Avoids DNS failure if Pi-hole\u2019s IP changes.</p>"},{"location":"services/pihole/proxmox_pihole_setup/#4-install-pi-hole","title":"4. Install Pi-hole","text":"<p>SSH in or use <code>pct exec</code>:</p> <pre><code>apt update &amp;&amp; apt upgrade -y\napt install curl -y\ncurl -sSL https://install.pi-hole.net | bash\n</code></pre> <p>Follow prompts: - Choose static IP - Choose DNS provider - Enable blocklists - Enable web interface and lighttpd</p>"},{"location":"services/pihole/proxmox_pihole_setup/#5-set-web-ui-password","title":"5. Set Web UI Password","text":"<pre><code>pihole -a -p\n</code></pre>"},{"location":"services/pihole/proxmox_pihole_setup/#6-access-web-interface","title":"6. Access Web Interface","text":"<p>Visit:</p> <pre><code>http://&lt;container-ip&gt;/admin\n</code></pre> <p>Login with the password you set.</p>"},{"location":"services/pihole/proxmox_pihole_setup/#7-configure-router-to-use-pi-hole","title":"7. Configure Router to Use Pi-hole","text":""},{"location":"services/pihole/proxmox_pihole_setup/#option-a-dhcp-dns","title":"Option A \u2013 DHCP DNS:","text":"<ul> <li>Set LAN DNS to <code>192.168.79.10</code></li> </ul>"},{"location":"services/pihole/proxmox_pihole_setup/#option-b-static-dns-per-device","title":"Option B \u2013 Static DNS per device","text":"<p>Why: This routes all network DNS through Pi-hole.</p>"},{"location":"services/pihole/proxmox_pihole_setup/#8-secure-and-harden","title":"8. Secure and Harden","text":"<pre><code>apt install unattended-upgrades -y\n</code></pre> <p>Add blocklists, optionally: - Back up <code>/etc/pihole/</code> - Consider <code>PiVPN</code> if remote access is needed</p>"},{"location":"services/pihole/proxmox_pihole_setup/#9-add-fail2ban-optional","title":"9. Add Fail2Ban (Optional)","text":"<pre><code>apt install fail2ban -y\n</code></pre>"},{"location":"services/pihole/proxmox_pihole_setup/#10-test-pi-hole","title":"10. Test Pi-hole","text":"<pre><code>nslookup google.com 192.168.79.10\n</code></pre> <p>Should reply from Pi-hole.</p>"},{"location":"services/pihole/proxmox_pihole_setup/#summary-table","title":"\ud83d\udccb Summary Table","text":"Step What You Do Why You Do It 1 Download Template Base image needed 2 Create LXC Lightweight, secure 3 Assign Static IP DNS reliability 4 Install Pi-hole Setup DNS blocker 5 Set Password Secures web UI 6 Configure Router Routes traffic 7 Harden System Keeps it updated 8 Enable Fail2Ban Adds login protection 9 Test Verifies it works"}]}